{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adriroma07/pyspark-kafka-colab/blob/main/Pyspark_Kafka_1_0_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDHGFU9wPNux"
      },
      "source": [
        "# **Install kafka in Google colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lD_ivW-sbm-",
        "outputId": "49501805-f958-4267-809a-2e510df715b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kafka-python\n",
            "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
            "\u001b[K     |████████████████████████████████| 246 kB 4.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: kafka-python\n",
            "Successfully installed kafka-python-2.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install kafka-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hic1Bs7usdK6"
      },
      "outputs": [],
      "source": [
        "!curl -sSOL https://downloads.apache.org/kafka/3.0.1/kafka_2.12-3.0.1.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnGhX3v_se0v"
      },
      "outputs": [],
      "source": [
        "!tar -xzf kafka_2.12-3.0.1.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaYluAQhsetp",
        "outputId": "8ee0c566-a6a7-49f2-9bd7-6b27a96acc33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for 10 secs until kafka and zookeeper services are up and running\n"
          ]
        }
      ],
      "source": [
        "!./kafka_2.12-3.0.1/bin/zookeeper-server-start.sh -daemon ./kafka_2.12-3.0.1/config/zookeeper.properties\n",
        "!./kafka_2.12-3.0.1/bin/kafka-server-start.sh -daemon ./kafka_2.12-3.0.1/config/server.properties\n",
        "!echo \"Waiting for 10 secs until kafka and zookeeper services are up and running\"\n",
        "!sleep 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-4Gr5_kspAO",
        "outputId": "cfd50914-ed0a-49c8-e5e7-da04d16d5879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root         475       1 19 15:32 ?        00:00:02 java -Xmx512M -Xms512M -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xlog:gc*:file=/content/kafka_2.12-3.0.1/bin/../logs/zookeeper-gc.log:time,tags:filecount=10,filesize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/content/kafka_2.12-3.0.1/bin/../logs -Dlog4j.configuration=file:./kafka_2.12-3.0.1/bin/../config/log4j.properties -cp /content/kafka_2.12-3.0.1/bin/../libs/activation-1.1.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/aopalliance-repackaged-2.6.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/argparse4j-0.7.0.jar:/content/kafka_2.12-3.0.1/bin/../libs/audience-annotations-0.5.0.jar:/content/kafka_2.12-3.0.1/bin/../libs/commons-cli-1.4.jar:/content/kafka_2.12-3.0.1/bin/../libs/commons-lang3-3.8.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-api-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-basic-auth-extension-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-file-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-json-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-mirror-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-mirror-client-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-runtime-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-transforms-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/hk2-api-2.6.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/hk2-locator-2.6.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/hk2-utils-2.6.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-annotations-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-core-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-databind-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-dataformat-csv-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-datatype-jdk8-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-jaxrs-base-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-jaxrs-json-provider-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-module-jaxb-annotations-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-module-scala_2.12-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/jakarta.annotation-api-1.3.5.jar:/content/kafka_2.12-3.0.1/bin/../libs/jakarta.inject-2.6.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/jakarta.validation-api-2.0.2.jar:/content/kafka_2.12-3.0.1/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/content/kafka_2.12-3.0.1/bin/../libs/javassist-3.27.0-GA.jar:/content/kafka_2.12-3.0.1/bin/../libs/javax.servlet-api-3.1.0.jar:/content/kafka_2.12-3.0.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/jaxb-api-2.3.0.jar:/content/kafka_2.12-3.0.1/bin/../libs/jersey-client-2.34.jar:/content/kafka_2.12-3.0.1/bin/../libs/jersey-common-2.34.jar:/content/kafka_2.12-3.0.1/bin/../libs/jersey-container-servlet-2.34.jar:/content/kafka_2.12-3.0.1/bin/../libs/jersey-container-servlet-core-2.34.jar:/content/kafka_2.12-3.0.1/bin/../libs/jersey-hk2-2.34.jar:/content/kafka_2.12-3.0.1/bin/../libs/jersey-server-2.34.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-client-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-continuation-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-http-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-io-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-security-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-server-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-servlet-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-servlets-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-util-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-util-ajax-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jline-3.12.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/jopt-simple-5.0.4.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka_2.12-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-clients-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-log4j-appender-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-metadata-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-raft-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-server-common-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-shell-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-storage-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-storage-api-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-streams-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-streams-examples-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-streams-scala_2.12-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-streams-test-utils-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-tools-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/log4j-1.2.17.jar:/content/kafka_2.12-3.0.1/bin/../libs/lz4-java-1.7.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/maven-artifact-3.8.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/metrics-core-2.2.0.jar:/content/kafka_2.12-3.0.1/bin/../libs/metrics-core-4.1.12.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-buffer-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-codec-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-common-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-handler-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-resolver-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-tcnative-classes-2.0.46.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-transport-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-transport-classes-epoll-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-transport-native-epoll-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-transport-native-unix-common-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/osgi-resource-locator-1.0.3.jar:/content/kafka_2.12-3.0.1/bin/../libs/paranamer-2.8.jar:/content/kafka_2.12-3.0.1/bin/../libs/plexus-utils-3.2.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/reflections-0.9.12.jar:/content/kafka_2.12-3.0.1/bin/../libs/rocksdbjni-6.19.3.jar:/content/kafka_2.12-3.0.1/bin/../libs/scala-collection-compat_2.12-2.4.4.jar:/content/kafka_2.12-3.0.1/bin/../libs/scala-java8-compat_2.12-1.0.0.jar:/content/kafka_2.12-3.0.1/bin/../libs/scala-library-2.12.14.jar:/content/kafka_2.12-3.0.1/bin/../libs/scala-logging_2.12-3.9.3.jar:/content/kafka_2.12-3.0.1/bin/../libs/scala-reflect-2.12.14.jar:/content/kafka_2.12-3.0.1/bin/../libs/slf4j-api-1.7.30.jar:/content/kafka_2.12-3.0.1/bin/../libs/slf4j-log4j12-1.7.30.jar:/content/kafka_2.12-3.0.1/bin/../libs/snappy-java-1.1.8.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/trogdor-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/zookeeper-3.6.3.jar:/content/kafka_2.12-3.0.1/bin/../libs/zookeeper-jute-3.6.3.jar:/content/kafka_2.12-3.0.1/bin/../libs/zstd-jni-1.5.0-2.jar org.apache.zookeeper.server.quorum.QuorumPeerMain ./kafka_2.12-3.0.1/config/zookeeper.properties\n",
            "root         821       1 68 15:32 ?        00:00:07 java -Xmx1G -Xms1G -server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent -XX:MaxInlineLevel=15 -Djava.awt.headless=true -Xlog:gc*:file=/content/kafka_2.12-3.0.1/bin/../logs/kafkaServer-gc.log:time,tags:filecount=10,filesize=100M -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dkafka.logs.dir=/content/kafka_2.12-3.0.1/bin/../logs -Dlog4j.configuration=file:./kafka_2.12-3.0.1/bin/../config/log4j.properties -cp /content/kafka_2.12-3.0.1/bin/../libs/activation-1.1.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/aopalliance-repackaged-2.6.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/argparse4j-0.7.0.jar:/content/kafka_2.12-3.0.1/bin/../libs/audience-annotations-0.5.0.jar:/content/kafka_2.12-3.0.1/bin/../libs/commons-cli-1.4.jar:/content/kafka_2.12-3.0.1/bin/../libs/commons-lang3-3.8.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-api-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-basic-auth-extension-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-file-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-json-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-mirror-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-mirror-client-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-runtime-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/connect-transforms-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/hk2-api-2.6.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/hk2-locator-2.6.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/hk2-utils-2.6.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-annotations-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-core-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-databind-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-dataformat-csv-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-datatype-jdk8-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-jaxrs-base-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-jaxrs-json-provider-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-module-jaxb-annotations-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jackson-module-scala_2.12-2.12.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jakarta.activation-api-1.2.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/jakarta.annotation-api-1.3.5.jar:/content/kafka_2.12-3.0.1/bin/../libs/jakarta.inject-2.6.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/jakarta.validation-api-2.0.2.jar:/content/kafka_2.12-3.0.1/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/content/kafka_2.12-3.0.1/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/content/kafka_2.12-3.0.1/bin/../libs/javassist-3.27.0-GA.jar:/content/kafka_2.12-3.0.1/bin/../libs/javax.servlet-api-3.1.0.jar:/content/kafka_2.12-3.0.1/bin/../libs/javax.ws.rs-api-2.1.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/jaxb-api-2.3.0.jar:/content/kafka_2.12-3.0.1/bin/../libs/jersey-client-2.34.jar:/content/kafka_2.12-3.0.1/bin/../libs/jersey-common-2.34.jar:/content/kafka_2.12-3.0.1/bin/../libs/jersey-container-servlet-2.34.jar:/content/kafka_2.12-3.0.1/bin/../libs/jersey-container-servlet-core-2.34.jar:/content/kafka_2.12-3.0.1/bin/../libs/jersey-hk2-2.34.jar:/content/kafka_2.12-3.0.1/bin/../libs/jersey-server-2.34.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-client-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-continuation-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-http-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-io-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-security-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-server-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-servlet-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-servlets-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-util-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jetty-util-ajax-9.4.44.v20210927.jar:/content/kafka_2.12-3.0.1/bin/../libs/jline-3.12.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/jopt-simple-5.0.4.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka_2.12-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-clients-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-log4j-appender-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-metadata-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-raft-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-server-common-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-shell-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-storage-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-storage-api-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-streams-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-streams-examples-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-streams-scala_2.12-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-streams-test-utils-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/kafka-tools-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/log4j-1.2.17.jar:/content/kafka_2.12-3.0.1/bin/../libs/lz4-java-1.7.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/maven-artifact-3.8.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/metrics-core-2.2.0.jar:/content/kafka_2.12-3.0.1/bin/../libs/metrics-core-4.1.12.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-buffer-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-codec-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-common-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-handler-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-resolver-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-tcnative-classes-2.0.46.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-transport-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-transport-classes-epoll-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-transport-native-epoll-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/netty-transport-native-unix-common-4.1.73.Final.jar:/content/kafka_2.12-3.0.1/bin/../libs/osgi-resource-locator-1.0.3.jar:/content/kafka_2.12-3.0.1/bin/../libs/paranamer-2.8.jar:/content/kafka_2.12-3.0.1/bin/../libs/plexus-utils-3.2.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/reflections-0.9.12.jar:/content/kafka_2.12-3.0.1/bin/../libs/rocksdbjni-6.19.3.jar:/content/kafka_2.12-3.0.1/bin/../libs/scala-collection-compat_2.12-2.4.4.jar:/content/kafka_2.12-3.0.1/bin/../libs/scala-java8-compat_2.12-1.0.0.jar:/content/kafka_2.12-3.0.1/bin/../libs/scala-library-2.12.14.jar:/content/kafka_2.12-3.0.1/bin/../libs/scala-logging_2.12-3.9.3.jar:/content/kafka_2.12-3.0.1/bin/../libs/scala-reflect-2.12.14.jar:/content/kafka_2.12-3.0.1/bin/../libs/slf4j-api-1.7.30.jar:/content/kafka_2.12-3.0.1/bin/../libs/slf4j-log4j12-1.7.30.jar:/content/kafka_2.12-3.0.1/bin/../libs/snappy-java-1.1.8.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/trogdor-3.0.1.jar:/content/kafka_2.12-3.0.1/bin/../libs/zookeeper-3.6.3.jar:/content/kafka_2.12-3.0.1/bin/../libs/zookeeper-jute-3.6.3.jar:/content/kafka_2.12-3.0.1/bin/../libs/zstd-jni-1.5.0-2.jar kafka.Kafka ./kafka_2.12-3.0.1/config/server.properties\n",
            "root         912      58  0 15:32 ?        00:00:00 /bin/bash -c ps -ef | grep kafka\n",
            "root         914     912  0 15:32 ?        00:00:00 grep kafka\n"
          ]
        }
      ],
      "source": [
        "!ps -ef | grep kafka"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkXOnLI0dmIJ"
      },
      "source": [
        "### Create input and output topics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMpm48JEeDp5"
      },
      "source": [
        "The topics have the following configuration:\n",
        "\n",
        "*   Replica = 1\n",
        "*   Partition = 1\n",
        "\n",
        "Se crean los diferentes topics:\n",
        "\n",
        "*   **wikipedia-events** = wikipedia streaming data entry topic.\n",
        "*   **outStreaming** = topic where the data is stored in kafka with the writerStream.\n",
        "*   **groupData** = output topic for aggregation with pivoting.\n",
        "*   **pivotData** = output topic for aggregation with grouping.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv3HYj2Zsj2x",
        "outputId": "90ceea0e-ab34-4837-9c12-aece6778b21a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created topic wikipedia-events.\n"
          ]
        }
      ],
      "source": [
        "!./kafka_2.12-3.0.1/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 1 --topic wikipedia-events"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suPwstnVnCZf",
        "outputId": "a9573738-3b2e-4108-cc0a-d28e00e52452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created topic outStreaming.\n"
          ]
        }
      ],
      "source": [
        "!./kafka_2.12-3.0.1/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 1 --topic outStreaming"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./kafka_2.12-3.0.1/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 1 --topic groupData"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBKskhJqO-3s",
        "outputId": "5cc77643-753f-4230-b52b-c8484c2e99d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created topic groupData.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4HaY_dsX4Pc",
        "outputId": "774bbb9d-9636-4c37-947a-3a4efbdd96f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created topic pivotData.\n"
          ]
        }
      ],
      "source": [
        "!./kafka_2.12-3.0.1/bin/kafka-topics.sh --create --bootstrap-server 127.0.0.1:9092 --replication-factor 1 --partitions 1 --topic pivotData"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfQCvogTfJ_S"
      },
      "source": [
        "# **Download spark, install libraries and download dependencies**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRaHvIelgp-6"
      },
      "source": [
        "To work in the environment, you have to update the system and download the version of java 8. Once installed, version 3.1.3 of spark is downloaded from the apache download page. In addition, pip installation of findspark, sseclient and pyspark is performed. Finally, we download different libraries that support spark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8Y8pnh0v0Th",
        "outputId": "f3543c82-bbb2-4551-9025-fac8fca3487e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [903 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,937 kB]\n",
            "Get:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,141 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,310 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,077 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,100 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,533 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,368 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,064 kB]\n",
            "Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 16.8 MB in 7s (2,316 kB/s)\n",
            "Reading package lists... Done\n",
            "--2022-08-10 15:34:56--  https://downloads.apache.org/spark/spark-3.1.3/spark-3.1.3-bin-hadoop2.7.tgz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.95.219, 2a01:4f8:10a:201a::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 227452039 (217M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.1.3-bin-hadoop2.7.tgz’\n",
            "\n",
            "spark-3.1.3-bin-had 100%[===================>] 216.92M  10.4MB/s    in 23s     \n",
            "\n",
            "2022-08-10 15:35:21 (9.29 MB/s) - ‘spark-3.1.3-bin-hadoop2.7.tgz’ saved [227452039/227452039]\n",
            "\n",
            "spark-3.1.3-bin-hadoop2.7/\n",
            "spark-3.1.3-bin-hadoop2.7/bin/\n",
            "spark-3.1.3-bin-hadoop2.7/bin/pyspark.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/spark-submit\n",
            "spark-3.1.3-bin-hadoop2.7/bin/spark-submit.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/spark-class2.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/spark-shell2.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/pyspark2.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/docker-image-tool.sh\n",
            "spark-3.1.3-bin-hadoop2.7/bin/run-example.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/spark-submit2.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/beeline.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/beeline\n",
            "spark-3.1.3-bin-hadoop2.7/bin/spark-shell\n",
            "spark-3.1.3-bin-hadoop2.7/bin/find-spark-home\n",
            "spark-3.1.3-bin-hadoop2.7/bin/sparkR2.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/find-spark-home.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/sparkR\n",
            "spark-3.1.3-bin-hadoop2.7/bin/spark-class\n",
            "spark-3.1.3-bin-hadoop2.7/bin/spark-sql2.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/load-spark-env.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/run-example\n",
            "spark-3.1.3-bin-hadoop2.7/bin/spark-sql\n",
            "spark-3.1.3-bin-hadoop2.7/bin/spark-class.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/spark-sql.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/spark-shell.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/sparkR.cmd\n",
            "spark-3.1.3-bin-hadoop2.7/bin/load-spark-env.sh\n",
            "spark-3.1.3-bin-hadoop2.7/bin/pyspark\n",
            "spark-3.1.3-bin-hadoop2.7/README.md\n",
            "spark-3.1.3-bin-hadoop2.7/R/\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/tests/\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/tests/testthat/\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/R/\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/R/SparkR\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/INDEX\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/worker/\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/worker/worker.R\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/help/\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/help/paths.rds\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/help/AnIndex\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/NAMESPACE\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/html/\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/html/00Index.html\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/html/R.css\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/profile/\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/profile/general.R\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/profile/shell.R\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/Meta/\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.1.3-bin-hadoop2.7/R/lib/sparkr.zip\n",
            "spark-3.1.3-bin-hadoop2.7/NOTICE\n",
            "spark-3.1.3-bin-hadoop2.7/data/\n",
            "spark-3.1.3-bin-hadoop2.7/data/graphx/\n",
            "spark-3.1.3-bin-hadoop2.7/data/graphx/followers.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/graphx/users.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/origin/\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/origin/multi-channel/\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/origin/license.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/origin/kittens/\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/images/license.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/ridge-data/\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/kmeans_data.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/iris_libsvm.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/als/\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/als/test.data\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/sample_lda_data.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/pagerank_data.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/gmm_data.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/pic_data.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/sample_movielens_data.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/mllib/sample_svm_data.txt\n",
            "spark-3.1.3-bin-hadoop2.7/data/streaming/\n",
            "spark-3.1.3-bin-hadoop2.7/data/streaming/AFINN-111.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-javolution.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-f2j.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-zstd.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-re2j.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-machinist.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-respond.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-kryo.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-modernizr.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-jline.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-jquery.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-mustache.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-CC0.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-protobuf.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-automaton.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-scopt.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-antlr.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-jodd.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-join.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-paranamer.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-arpack.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-slf4j.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-datatables.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-py4j.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-janino.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-scala.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-javassist.html\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-minlog.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-netlib.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.1.3-bin-hadoop2.7/licenses/LICENSE-spire.txt\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/tests/\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/tests/pyfiles.py\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/tests/py_container_checks.py\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/tests/python_executable_check.py\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/tests/decommissioning.py\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/tests/autoscale.py\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/dockerfiles/\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.1.3-bin-hadoop2.7/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.1.3-bin-hadoop2.7/examples/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/dir1/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/employees.json\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/people.txt\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/users.avro\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/people.json\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/user.avsc\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/users.parquet\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/people.csv\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/users.orc\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/full_user.avsc\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/resources/kv1.txt\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scripts/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/status_api_demo.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/pagerank.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/sort.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/transitive_closure.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/wordcount.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/logistic_regression.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/als_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/kmeans.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/streaming/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/als.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/pi.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/sql/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/sql/datasource.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/sql/hive.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/sql/arrow.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/sql/streaming/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/python/sql/basic.py\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/dataframe.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/data-manipulation.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/lda.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/glm.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/kstest.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/gbt.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/als.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/survreg.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/logit.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/mlp.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/ml.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/fpm.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/streaming/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.1.3-bin-hadoop2.7/examples/jars/\n",
            "spark-3.1.3-bin-hadoop2.7/examples/jars/spark-examples_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/LICENSE\n",
            "spark-3.1.3-bin-hadoop2.7/RELEASE\n",
            "spark-3.1.3-bin-hadoop2.7/python/\n",
            "spark-3.1.3-bin-hadoop2.7/python/MANIFEST.in\n",
            "spark-3.1.3-bin-hadoop2.7/python/mypy.ini\n",
            "spark-3.1.3-bin-hadoop2.7/python/README.md\n",
            "spark-3.1.3-bin-hadoop2.7/python/run-tests.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pylintrc\n",
            "spark-3.1.3-bin-hadoop2.7/python/run-tests-with-coverage\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_coverage/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_coverage/coverage_daemon.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_coverage/sitecustomize.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_coverage/conf/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/userlibrary.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/userlib-0.1.zip\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/hello/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/hello/sub_hello/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/hello/hello.txt\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_metadata\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_SUCCESS\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/parquet_partitioned/_common_metadata\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/people.json\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/ages.csv\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/text-test.txt\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/streaming/\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/people1.json\n",
            "spark-3.1.3-bin-hadoop2.7/python/test_support/sql/people_array.json\n",
            "spark-3.1.3-bin-hadoop2.7/python/setup.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/lib/\n",
            "spark-3.1.3-bin-hadoop2.7/python/lib/pyspark.zip\n",
            "spark-3.1.3-bin-hadoop2.7/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.1.3-bin-hadoop2.7/python/lib/py4j-0.10.9-src.zip\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/make.bat\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/make2.bat\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/Makefile\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/user_guide/\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/user_guide/index.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/reference/\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/reference/pyspark.ss.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/reference/pyspark.sql.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/reference/pyspark.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/reference/index.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/development/\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/development/setting_ide.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/development/testing.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/development/debugging.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/development/contributing.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/development/index.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/getting_started/\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/getting_started/install.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/getting_started/index.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/getting_started/quickstart.ipynb\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/index.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/_static/\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/_static/css/\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/_static/copybutton.js\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/migration_guide/\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/migration_guide/index.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/_templates/\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/_templates/autosummary/\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.1.3-bin-hadoop2.7/python/docs/source/conf.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/.coveragerc\n",
            "spark-3.1.3-bin-hadoop2.7/python/run-tests\n",
            "spark-3.1.3-bin-hadoop2.7/python/.gitignore\n",
            "spark-3.1.3-bin-hadoop2.7/python/setup.cfg\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/accumulators.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/rdd.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/profiler.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_worker.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_util.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_serializers.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_conf.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_rdd.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_join.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_context.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_profiler.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/tests/test_daemon.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/rdd.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/java_gateway.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/resultiterable.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/daemon.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/testing/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/testing/mlutils.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/testing/streamingutils.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/testing/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/testing/utils.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/testing/mllibutils.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/testing/sqlutils.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/find_spark_home.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/util.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/random.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/regression.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/clustering.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/tests/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/common.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/tree.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/regression.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/util.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/evaluation.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/feature.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/linalg/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/linalg/__init__.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/feature.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/classification.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/recommendation.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/clustering.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/common.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/fpm.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/tree.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/stat/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/stat/test.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/stat/distribution.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/stat/__init__.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/stat/_statistics.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/stat/test.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/classification.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/fpm.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/recommendation.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/evaluation.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/mllib/random.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/install.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/shell.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/cloudpickle/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/shuffle.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/util.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/_globals.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/conf.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/resource/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/resource/tests/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/resource/profile.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/resource/requests.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/resource/requests.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/resource/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/resource/information.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/resource/information.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/resource/profile.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/context.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/storagelevel.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/status.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/py.typed\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/version.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/version.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/serializers.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/statcounter.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/worker.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/join.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/rddsampler.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/resultiterable.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/util.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/regression.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/clustering.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/stat.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/test_tuning.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tuning.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/common.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tree.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/param/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/param/shared.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/param/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/param/shared.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/param/__init__.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/param/_shared_params_code_gen.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/wrapper.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/regression.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/functions.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/base.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/stat.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/util.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/image.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/evaluation.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/feature.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/linalg/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/linalg/__init__.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/feature.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/classification.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/pipeline.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/image.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/recommendation.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/clustering.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/common.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/wrapper.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/fpm.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/base.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tree.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/functions.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/classification.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/_typing.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/fpm.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/recommendation.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/tuning.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/evaluation.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/ml/pipeline.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/files.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/broadcast.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/taskcontext.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/broadcast.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/status.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/tests/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/kinesis.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/util.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/context.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/listener.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/dstream.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/dstream.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/kinesis.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/context.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/streaming/listener.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/traceback_utils.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/__init__.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/storagelevel.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/files.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/_typing.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/taskcontext.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/context.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/profiler.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/accumulators.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/statcounter.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/conf.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/group.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_streaming.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_grouped_map.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_map.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_pandas_udf_window.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/dataframe.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/udf.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/types.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/functions.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/group.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/session.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/conf.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/column.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/column.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/context.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/avro/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/avro/functions.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/avro/functions.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/streaming.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/streaming.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/window.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/readwriter.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/group_ops.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/types.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/map_ops.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/utils.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/catalog.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/readwriter.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/__init__.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/window.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/types.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/dataframe.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/functions.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/catalog.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/_typing.pyi\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/context.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/session.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/udf.py\n",
            "spark-3.1.3-bin-hadoop2.7/python/pyspark/sql/conf.py\n",
            "spark-3.1.3-bin-hadoop2.7/yarn/\n",
            "spark-3.1.3-bin-hadoop2.7/yarn/spark-3.1.3-yarn-shuffle.jar\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/decommission-slave.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/stop-all.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/stop-slave.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/stop-slaves.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/start-worker.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/stop-worker.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/stop-workers.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/spark-daemons.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/stop-master.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/start-thriftserver.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/stop-thriftserver.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/start-workers.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/start-slaves.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/spark-config.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/start-master.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/spark-daemon.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/workers.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/start-slave.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/start-all.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/start-history-server.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/decommission-worker.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/stop-history-server.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.1.3-bin-hadoop2.7/sbin/slaves.sh\n",
            "spark-3.1.3-bin-hadoop2.7/jars/\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-batch-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/api-asn1-api-1.0.0-M20.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/apacheds-kerberos-codec-2.0.0-M15.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/arrow-format-2.0.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/netty-all-4.1.51.Final.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/JTransforms-3.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/avro-mapred-1.8.2-hadoop2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-jdbc-2.3.7.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/protobuf-java-2.5.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-beeline-2.3.7.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-math3-3.4.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/parquet-common-1.10.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-mapreduce-client-core-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jaxb-api-2.2.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/ivy-2.4.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-hive_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jackson-core-2.10.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/zookeeper-3.4.14.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/scala-reflect-2.12.10.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-graphx_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/stax-api-1.0.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/htrace-core-3.1.0-incubating.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-tags_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-certificates-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-sketch_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/janino-3.0.16.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spire-util_2.12-0.17.0-M1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/HikariCP-2.5.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/algebra_2.12-2.0.0-M2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-mapreduce-client-app-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jpam-1.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/oro-2.0.8.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-net-3.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-yarn-server-web-proxy-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-apiextensions-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jackson-annotations-2.10.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/snappy-java-1.1.8.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/json4s-jackson_2.12-3.7.0-M5.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/metrics-core-4.1.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-shims-2.3.7.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/arrow-vector-2.0.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/json4s-core_2.12-3.7.0-M5.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/chill_2.12-0.9.5.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/threeten-extra-1.5.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/objenesis-2.6.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-core-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-metastore-2.3.7.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-cli-1.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/avro-ipc-1.8.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/cats-kernel_2.12-2.0.0-M4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/joda-time-2.10.5.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jcl-over-slf4j-1.7.30.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jackson-jaxrs-1.9.13.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/log4j-1.2.17.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jodd-core-3.5.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spire-macros_2.12-0.17.0-M1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jsr305-3.0.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jakarta.activation-api-1.2.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-auth-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-shims-0.23-2.3.7.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/stream-2.9.6.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-vector-code-gen-2.3.7.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/xmlenc-0.52.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/automaton-1.11-8.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-network-shuffle_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/json4s-scalap_2.12-3.7.0-M5.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-compress-1.21.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/core-1.1.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jackson-module-paranamer-2.10.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jta-1.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jdo-api-3.0.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/velocity-1.5.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/httpclient-4.5.6.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/transaction-api-1.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/zstd-jni-1.4.8-1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spire_2.12-0.17.0-M1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-yarn-client-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/javax.inject-1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-extensions-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-lang3-3.10.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-storageclass-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/super-csv-2.2.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-policy-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-sql_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/scala-parser-combinators_2.12-1.1.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/javolution-5.5.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/slf4j-log4j12-1.7.30.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/paranamer-2.8.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/scala-xml_2.12-1.2.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/xbean-asm7-shaded-4.15.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-catalyst_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-launcher_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/py4j-0.10.9.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-admissionregistration-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-client-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/apacheds-i18n-2.0.0-M15.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/compress-lzf-1.0.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/generex-1.0.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-beanutils-1.9.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/curator-recipes-2.7.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jetty-util-6.1.26.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-streaming_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-dbcp-1.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/metrics-jvm-4.1.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/api-util-1.0.0-M20.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/orc-shims-1.5.13.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-yarn-common-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/JLargeArrays-1.5.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-shims-common-2.3.7.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-autoscaling-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jersey-server-2.30.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/libfb303-0.9.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-kvstore_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-serde-2.3.7.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/aopalliance-1.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jersey-container-servlet-2.30.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-scheduling-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-annotations-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jackson-dataformat-yaml-2.10.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jline-2.14.6.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/xz-1.5.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/tink-1.6.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-common-2.3.7.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/libthrift-0.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/shapeless_2.12-2.3.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-shims-scheduler-2.3.7.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/snakeyaml-1.24.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/xercesImpl-2.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/activation-1.1.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-client-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-compiler-3.0.16.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-mapreduce-client-common-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jul-to-slf4j-1.7.30.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-apps-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/json-1.8.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/avro-1.8.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/orc-mapreduce-1.5.13.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-network-common_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/scala-library-2.12.10.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/okio-1.14.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-io-2.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-tags_2.12-3.1.3-tests.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jsp-api-2.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/parquet-encoding-1.10.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-metrics-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/scala-compiler-2.12.10.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/RoaringBitmap-0.9.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/ST4-4.0.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/slf4j-api-1.7.30.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-codec-1.10.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jetty-sslengine-6.1.26.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/arrow-memory-core-2.0.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-hive-thriftserver_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/machinist_2.12-0.6.8.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-coordination-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-text-1.6.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-logging-1.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-core_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-mllib_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-mllib-local_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hk2-api-2.6.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-rbac-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/aircompressor-0.10.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/parquet-hadoop-1.10.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-discovery-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/parquet-format-2.4.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/guice-servlet-3.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-digester-1.8.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/okhttp-3.12.12.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/xml-apis-1.4.01.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/metrics-json-4.1.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/curator-client-2.7.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/httpcore-4.4.12.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spire-platform_2.12-0.17.0-M1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-storage-api-2.7.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-mesos_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/minlog-1.3.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jackson-databind-2.10.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-exec-2.3.7-core.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jackson-module-jaxb-annotations-2.10.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/shims-0.9.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/metrics-jmx-4.1.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-unsafe_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-networking-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/chill-java-0.9.5.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/breeze_2.12-1.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/antlr4-runtime-4.8-1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/orc-core-1.5.13.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/guava-14.0.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-cli-2.3.7.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jersey-media-jaxb-2.30.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/parquet-column-1.10.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jersey-container-servlet-core-2.30.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-httpclient-3.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-events-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/mesos-1.4.0-shaded-protobuf.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jersey-common-2.30.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jersey-client-2.30.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-pool-1.5.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-lang-2.6.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/flatbuffers-java-1.9.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/stax-api-1.0-2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-service-rpc-3.1.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-mapreduce-client-jobclient-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/curator-framework-2.7.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/opencsv-2.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/metrics-graphite-4.1.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/parquet-jackson-1.10.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jackson-datatype-jsr310-2.11.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-yarn-api-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jetty-6.1.26.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-hdfs-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-yarn-server-common-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jersey-hk2-2.30.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/lz4-java-1.7.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/pyrolite-4.30.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-settings-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/scala-collection-compat_2.12-2.1.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/guice-3.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/macro-compat_2.12-1.1.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/kubernetes-model-common-4.12.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-kubernetes_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hive-llap-common-2.3.7.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/derby-10.12.1.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/gson-2.2.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-configuration-1.6.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jackson-xc-1.9.13.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/breeze-macros_2.12-1.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-repl_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/javassist-3.25.0-GA.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-common-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/arrow-memory-netty-2.0.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/hadoop-mapreduce-client-shuffle-2.7.4.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/jackson-module-scala_2.12-2.10.0.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/commons-collections-3.2.2.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/spark-yarn_2.12-3.1.3.jar\n",
            "spark-3.1.3-bin-hadoop2.7/jars/json4s-ast_2.12-3.7.0-M5.jar\n",
            "spark-3.1.3-bin-hadoop2.7/conf/\n",
            "spark-3.1.3-bin-hadoop2.7/conf/metrics.properties.template\n",
            "spark-3.1.3-bin-hadoop2.7/conf/fairscheduler.xml.template\n",
            "spark-3.1.3-bin-hadoop2.7/conf/workers.template\n",
            "spark-3.1.3-bin-hadoop2.7/conf/spark-env.sh.template\n",
            "spark-3.1.3-bin-hadoop2.7/conf/log4j.properties.template\n",
            "spark-3.1.3-bin-hadoop2.7/conf/spark-defaults.conf.template\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 47 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 47.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=63524bcd472d076795b38e7d7137d38b82854b883d290315ee81a3949f05a184\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n",
            "--2022-08-10 15:36:22--  https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-10-assembly_2.12/3.1.3/spark-streaming-kafka-0-10-assembly_2.12-3.1.3.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31889848 (30M) [application/java-archive]\n",
            "Saving to: ‘spark-streaming-kafka-0-10-assembly_2.12-3.1.3.jar’\n",
            "\n",
            "spark-streaming-kaf 100%[===================>]  30.41M  15.6MB/s    in 1.9s    \n",
            "\n",
            "2022-08-10 15:36:24 (15.6 MB/s) - ‘spark-streaming-kafka-0-10-assembly_2.12-3.1.3.jar’ saved [31889848/31889848]\n",
            "\n",
            "--2022-08-10 15:36:24--  https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.1.3/spark-sql-kafka-0-10_2.12-3.1.3.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 387493 (378K) [application/java-archive]\n",
            "Saving to: ‘spark-sql-kafka-0-10_2.12-3.1.3.jar’\n",
            "\n",
            "spark-sql-kafka-0-1 100%[===================>] 378.41K   915KB/s    in 0.4s    \n",
            "\n",
            "2022-08-10 15:36:25 (915 KB/s) - ‘spark-sql-kafka-0-10_2.12-3.1.3.jar’ saved [387493/387493]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --------- Spark -----------\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget https://downloads.apache.org/spark/spark-3.1.3/spark-3.1.3-bin-hadoop2.7.tgz\n",
        "!tar -xvf spark-3.1.3-bin-hadoop2.7.tgz\n",
        "!pip install findspark\n",
        "!pip install pyspark\n",
        "!wget \"https://repo1.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-10-assembly_2.12/3.1.3/spark-streaming-kafka-0-10-assembly_2.12-3.1.3.jar\"\n",
        "!wget \"https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.1.3/spark-sql-kafka-0-10_2.12-3.1.3.jar\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWBVUI5_4AiD"
      },
      "source": [
        "### Imports and sets "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qpJHGm9g_pq"
      },
      "source": [
        "Modify the JAVA_HOME environment variable, add the SPARK_HOME variable and include the PYSPARK_SUBMIT_ARGS variable."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice\n",
        "import json\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "from datetime import datetime\n",
        "import threading"
      ],
      "metadata": {
        "id": "-eDE4Di6GFLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSQSKNsMPq4Q",
        "outputId": "17263b87-5fab-4d2d-ea5c-708a1d44dc96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n"
          ]
        }
      ],
      "source": [
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.3-bin-hadoop2.7\"\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /content/spark-sql-kafka-0-10_2.12-3.1.3.jar pyspark-shell'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVY4FMQCiVhS"
      },
      "source": [
        "# **Initialize findspark and create a sparkSession in Colab.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "gwdCi4EXGNhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1myVaPl6u1Ts"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "import time\n",
        "import threading\n",
        "import json\n",
        "from kafka import KafkaProducer\n",
        "from kafka.errors import KafkaError\n",
        "import time\n",
        "import requests\n",
        "from kafka import KafkaProducer\n",
        "from json import dumps\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYHmmmsliRpH"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml.feature import Normalizer, StandardScaler\n",
        "import random\n",
        "import pyspark\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.streaming import StreamingContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G47Iv-PBtz1u",
        "outputId": "10ac8976-1d3e-42bf-b2f4-9c4ab4c83f80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.1.3-bin-hadoop2.7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "findspark.find()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPEJ3ozIt77h"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .config('spark.jars.packages','org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.3')\\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RHh1FUZh1vg"
      },
      "source": [
        "# **Real-Time Data Extraction Wikipedia**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZgtWW0_i7jU"
      },
      "source": [
        "In the following section, the methods that make communication with https://stream.wikimedia.org/v2/stream/recentchange possible to extract the recent changes made by users in Wiki are developed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdgmlcBTisr6"
      },
      "source": [
        "**def init_namespaces():** Method that creates the first structure of the message."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sseclient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znbWjbCkGoyy",
        "outputId": "ef7f9383-1248-4618-f849-046648f5f019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sseclient\n",
            "  Downloading sseclient-0.0.27.tar.gz (7.5 kB)\n",
            "Requirement already satisfied: requests>=2.9 in /usr/local/lib/python3.7/dist-packages (from sseclient) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sseclient) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9->sseclient) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9->sseclient) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9->sseclient) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.9->sseclient) (2022.6.15)\n",
            "Building wheels for collected packages: sseclient\n",
            "  Building wheel for sseclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sseclient: filename=sseclient-0.0.27-py3-none-any.whl size=5584 sha256=538e5c1bfdfaf614a1ca567ee4c41ab1b4adcfc81bbd9c8fdc0e01907e66fc11\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/67/7e/96edf627ac746de1a5c5cbb8d59ed960f033b8352dc12c545d\n",
            "Successfully built sseclient\n",
            "Installing collected packages: sseclient\n",
            "Successfully installed sseclient-0.0.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3oyYS5WsL5A"
      },
      "outputs": [],
      "source": [
        "def init_namespaces():\n",
        "    # create a dictionary for the various known namespaces\n",
        "    # more info https://en.wikipedia.org/wiki/Wikipedia:Namespace#Programming\n",
        "    namespace_dict = {-2: 'Media', \n",
        "                      -1: 'Special', \n",
        "                      0: 'main namespace', \n",
        "                      1: 'Talk', \n",
        "                      2: 'User', 3: 'User Talk',\n",
        "                      4: 'Wikipedia', 5: 'Wikipedia Talk', \n",
        "                      6: 'File', 7: 'File Talk',\n",
        "                      8: 'MediaWiki', 9: 'MediaWiki Talk', \n",
        "                      10: 'Template', 11: 'Template Talk', \n",
        "                      12: 'Help', 13: 'Help Talk', \n",
        "                      14: 'Category', 15: 'Category Talk', \n",
        "                      100: 'Portal', 101: 'Portal Talk',\n",
        "                      108: 'Book', 109: 'Book Talk', \n",
        "                      118: 'Draft', 119: 'Draft Talk', \n",
        "                      446: 'Education Program', 447: 'Education Program Talk', \n",
        "                      710: 'TimedText', 711: 'TimedText Talk', \n",
        "                      828: 'Module', 829: 'Module Talk', \n",
        "                      2300: 'Gadget', 2301: 'Gadget Talk', \n",
        "                      2302: 'Gadget definition', 2303: 'Gadget definition Talk'}\n",
        "\n",
        "    return namespace_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ61Q7Mtjti_"
      },
      "source": [
        "**def construct_event(event_data, user_types):** \n",
        "Method that defines the structure of the json event"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cviX-orsJ8J"
      },
      "outputs": [],
      "source": [
        "def construct_event(event_data, user_types):\n",
        "    # use dictionary to change assign namespace value and catch any unknown namespaces (like ns 104)\n",
        "    try:\n",
        "        event_data['namespace'] = namespace_dict[event_data['namespace']]\n",
        "    except KeyError:\n",
        "        event_data['namespace'] = 'unknown'\n",
        "\n",
        "    # assign user type value to either bot or human\n",
        "    user_type = user_types[event_data['bot']]\n",
        "\n",
        "    # define the structure of the json event that will be published to kafka topic\n",
        "    event = {\"id\": event_data['id'],\n",
        "             \"domain\": event_data['meta']['domain'],\n",
        "             \"namespace\": event_data['namespace'],\n",
        "             \"title\": event_data['title'],\n",
        "             \"timestamp\": event_data['meta']['dt'],\n",
        "             \"user_name\": event_data['user'],\n",
        "             \"user_type\": user_type,\n",
        "             \"old_length\": event_data['length']['old'],\n",
        "             \"new_length\": event_data['length']['new']}\n",
        "    \n",
        "    return event"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4pB_r3Tj7YP"
      },
      "source": [
        "In the following code cell, the kafka producer is initialized, where the events will be inserted in json format. \n",
        "In addition, the topic is read in streaming and the WriteStream is used to save only the value field."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run for a few seconds and stop running."
      ],
      "metadata": {
        "id": "pfF1fDP9HIOa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5vwePwTsNnA",
        "outputId": "fd35f18d-4594-41c4-8351-cc7d3d6b9117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Event Streaming: {'id': 1753863194, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q12499275', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'Danil Satria', 'user_type': 'human', 'old_length': 22868, 'new_length': 23321}\n",
            "Event Streaming: {'id': 150767170, 'domain': 'zh.wikipedia.org', 'namespace': 'main namespace', 'title': '中国大陆电视剧列表 (2022年)', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'Musicinsummer', 'user_type': 'human', 'old_length': 217210, 'new_length': 217210}\n",
            "Event Streaming: {'id': 1753863197, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q12514428', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'Danil Satria', 'user_type': 'human', 'old_length': 12211, 'new_length': 11797}\n",
            "Event Streaming: {'id': 1753863196, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q79330348', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'Renamerr', 'user_type': 'human', 'old_length': 15911, 'new_length': 16044}\n",
            "Event Streaming: {'id': 1753863195, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q72259451', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'Renamerr', 'user_type': 'human', 'old_length': 29417, 'new_length': 29550}\n",
            "Event Streaming: {'id': 1753863198, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q113487283', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'Yiyi', 'user_type': 'human', 'old_length': 876, 'new_length': 1297}\n",
            "Event Streaming: {'id': 1753863199, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q108120555', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'Thomasstjerne', 'user_type': 'human', 'old_length': 6816, 'new_length': 7534}\n",
            "Event Streaming: {'id': 1753863200, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q11039550', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'Danil Satria', 'user_type': 'human', 'old_length': 12461, 'new_length': 12047}\n",
            "Event Streaming: {'id': 1753863201, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q19726398', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'Danil Satria', 'user_type': 'human', 'old_length': 10804, 'new_length': 10390}\n",
            "Event Streaming: {'id': 1753863202, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q73922375', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Renamerr', 'user_type': 'human', 'old_length': 23523, 'new_length': 23656}\n",
            "Event Streaming: {'id': 1753863204, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q116982', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Danil Satria', 'user_type': 'human', 'old_length': 19156, 'new_length': 19609}\n",
            "Event Streaming: {'id': 472769508, 'domain': 'fr.wikipedia.org', 'namespace': 'main namespace', 'title': 'Cité de la musique - Philharmonie de Paris', 'timestamp': '2022-08-10T15:37:21Z', 'user_name': 'Pandamou', 'user_type': 'human', 'old_length': 8877, 'new_length': 8769}\n",
            "Event Streaming: {'id': 1753863203, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q374807', 'timestamp': '2022-08-10T15:37:19Z', 'user_name': 'HarryNº2', 'user_type': 'human', 'old_length': 35112, 'new_length': 28583}\n",
            "Event Streaming: {'id': 272415891, 'domain': 'es.wikipedia.org', 'namespace': 'main namespace', 'title': 'Secretaría de Justicia (Argentina)', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': '190.139.97.212', 'user_type': 'human', 'old_length': 9940, 'new_length': 9943}\n",
            "Event Streaming: {'id': 1753863205, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q113487032', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Trilotat', 'user_type': 'human', 'old_length': 5204, 'new_length': 5190}\n",
            "Event Streaming: {'id': 86214474, 'domain': 'no.wikipedia.org', 'namespace': 'main namespace', 'title': 'Mummitrollet (figur)', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'Annelingua', 'user_type': 'human', 'old_length': 1592, 'new_length': 1686}\n",
            "Event Streaming: {'id': 1753863206, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q12514429', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Danil Satria', 'user_type': 'human', 'old_length': 13921, 'new_length': 13507}\n",
            "Event Streaming: {'id': 1753863207, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q12499275', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Danil Satria', 'user_type': 'human', 'old_length': 23321, 'new_length': 23774}\n",
            "Event Streaming: {'id': 1753863208, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q88710664', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Twofivesixbot', 'user_type': 'bot', 'old_length': 34427, 'new_length': 33725}\n",
            "Event Streaming: {'id': 1989627639, 'domain': 'commons.wikimedia.org', 'namespace': 'File', 'title': 'File:Schloß Neuhaus - Schloßstraße 6 - 1.jpg', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'BotMultichillT', 'user_type': 'bot', 'old_length': 3685, 'new_length': 4121}\n",
            "Event Streaming: {'id': 272415892, 'domain': 'es.wikipedia.org', 'namespace': 'main namespace', 'title': 'Sporting Clube de Braga', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'InternetArchiveBot', 'user_type': 'bot', 'old_length': 37613, 'new_length': 37988}\n",
            "Event Streaming: {'id': 1753863209, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q67817076', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Cewbot', 'user_type': 'bot', 'old_length': 23876, 'new_length': 28437}\n",
            "Event Streaming: {'id': 18942085, 'domain': 'simple.wikipedia.org', 'namespace': 'main namespace', 'title': 'National aquatic marine mammal of India', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'MathXplore', 'user_type': 'human', 'old_length': 39, 'new_length': 92}\n",
            "Event Streaming: {'id': 54210546, 'domain': 'tr.wikipedia.org', 'namespace': 'main namespace', 'title': 'Akoluk, Tuzluca', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'YBot', 'user_type': 'bot', 'old_length': 12447, 'new_length': 12427}\n",
            "Event Streaming: {'id': 1989627640, 'domain': 'commons.wikimedia.org', 'namespace': 'File', 'title': 'File:Hello Again Photo Call - 5569081298.jpg', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'SchlurcherBot', 'user_type': 'bot', 'old_length': 2474, 'new_length': 6514}\n",
            "Event Streaming: {'id': 1753863210, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q19561696', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Romaine', 'user_type': 'human', 'old_length': 6468, 'new_length': 6899}\n",
            "Event Streaming: {'id': 1753863211, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q19726402', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Danil Satria', 'user_type': 'human', 'old_length': 11426, 'new_length': 11012}\n",
            "Event Streaming: {'id': 1989627641, 'domain': 'commons.wikimedia.org', 'namespace': 'File', 'title': 'File:ISS030-E-160514 - View of Earth.jpg', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'AskeBot', 'user_type': 'bot', 'old_length': 10466, 'new_length': 10048}\n",
            "Event Streaming: {'id': 1753863212, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q10474681', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'SR5', 'user_type': 'human', 'old_length': 2322, 'new_length': 3521}\n",
            "Event Streaming: {'id': 1753863213, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q116982', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Danil Satria', 'user_type': 'human', 'old_length': 19609, 'new_length': 20062}\n",
            "Event Streaming: {'id': 1989627642, 'domain': 'commons.wikimedia.org', 'namespace': 'File', 'title': 'File:Groningen (stad), Martinitoren in Groningen. 13-06-2022. (actm.) 03.jpg', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Agnes Monkelbaan', 'user_type': 'human', 'old_length': 9251, 'new_length': 9534}\n",
            "Event Streaming: {'id': 1753863214, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q79330505', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Renamerr', 'user_type': 'human', 'old_length': 63707, 'new_length': 63840}\n",
            "Event Streaming: {'id': 1753863216, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q11039572', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Danil Satria', 'user_type': 'human', 'old_length': 12759, 'new_length': 12345}\n",
            "Event Streaming: {'id': 1753863215, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q73923087', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Renamerr', 'user_type': 'human', 'old_length': 27717, 'new_length': 27850}\n",
            "Event Streaming: {'id': 1753863217, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q108120566', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Thomasstjerne', 'user_type': 'human', 'old_length': 5947, 'new_length': 6665}\n",
            "Event Streaming: {'id': 1753863218, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q67817076', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Cewbot', 'user_type': 'bot', 'old_length': 28437, 'new_length': 28435}\n",
            "Event Streaming: {'id': 1753863219, 'domain': 'www.wikidata.org', 'namespace': 'main namespace', 'title': 'Q12499275', 'timestamp': '2022-08-10T15:37:23Z', 'user_name': 'Danil Satria', 'user_type': 'human', 'old_length': 23774, 'new_length': 24227}\n",
            "Event Streaming: {'id': 1537382771, 'domain': 'en.wikipedia.org', 'namespace': 'Talk', 'title': 'Talk:Pan-American Highway (North America)', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'Community Tech bot', 'user_type': 'human', 'old_length': 3419, 'new_length': 4058}\n",
            "Event Streaming: {'id': 39739901, 'domain': 'arz.wikipedia.org', 'namespace': 'main namespace', 'title': 'SHELS 012.969916+11.887112 (مجره)', 'timestamp': '2022-08-10T15:37:22Z', 'user_name': 'InternetArchiveBot', 'user_type': 'bot', 'old_length': 3546, 'new_length': 3688}\n",
            "process interrupted\n"
          ]
        }
      ],
      "source": [
        "producer = KafkaProducer(bootstrap_servers=\"localhost:9092\", value_serializer=lambda x: dumps(x).encode('utf-8'),api_version=(0, 10, 1))\n",
        "\n",
        "# used to parse user type\n",
        "user_types = {True: 'bot', False: 'human'}\n",
        " \n",
        "# init dictionary of namespaces\n",
        "namespace_dict = init_namespaces()\n",
        "\n",
        "import json\n",
        "from sseclient import SSEClient as EventSource\n",
        "\n",
        "url = 'https://stream.wikimedia.org/v2/stream/recentchange'\n",
        "try:\n",
        "  for event in EventSource(url):\n",
        "      if event.event == 'message':\n",
        "          try:\n",
        "              change = json.loads(event.data)\n",
        "              if change['type'] == 'edit':\n",
        "                # construct valid json event\n",
        "                event_to_send = construct_event(change, user_types)\n",
        "                print(\"Event Streaming:\",  event_to_send)   \n",
        "                producer.send(\"wikipedia-events\", value=event_to_send)\n",
        "\n",
        "                dfWikiStream = spark \\\n",
        "                  .readStream \\\n",
        "                  .format(\"kafka\") \\\n",
        "                  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
        "                  .option(\"subscribe\", \"wikipedia-events\") \\\n",
        "                  .load()\n",
        "                dfWikiFinalStream = dfWikiStream.selectExpr(\"CAST(value AS STRING)\")\n",
        "\n",
        "                ds = dfWikiStream \\\n",
        "                  .selectExpr(\"CAST(value AS STRING)\") \\\n",
        "                  .writeStream \\\n",
        "                  .format(\"kafka\") \\\n",
        "                  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
        "                  .option(\"topic\", \"outStreaming\") \\\n",
        "                  .option(\"checkpointLocation\", \"/content/checkpoint\") \\\n",
        "                  .start()\n",
        "                  \n",
        "          except ValueError:\n",
        "              pass\n",
        "except KeyboardInterrupt:\n",
        "    print(\"process interrupted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhJReQF9ytGU"
      },
      "outputs": [],
      "source": [
        "dfWiki = spark \\\n",
        "  .read \\\n",
        "  .format(\"kafka\") \\\n",
        "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
        "  .option(\"subscribe\", \"wikipedia-events\") \\\n",
        "  .load()\n",
        "dfWikiFinal = dfWiki.selectExpr(\"CAST(value AS STRING)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cMtdPKrfQrE"
      },
      "source": [
        "# **Data transformation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "jrjZ0HBDqi2l",
        "outputId": "0ac8d01a-3821-46cd-dee1-d523a6f67b44"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(dfWikiFinal.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrV3UQbjjBz1",
        "outputId": "74d98ca1-4b96-4bfb-aa9f-e5650b780ded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               value|\n",
            "+--------------------+\n",
            "|{\"id\": 1753863194...|\n",
            "|{\"id\": 150767170,...|\n",
            "|{\"id\": 1753863197...|\n",
            "|{\"id\": 1753863196...|\n",
            "|{\"id\": 1753863195...|\n",
            "|{\"id\": 1753863198...|\n",
            "|{\"id\": 1753863199...|\n",
            "|{\"id\": 1753863200...|\n",
            "|{\"id\": 1753863201...|\n",
            "|{\"id\": 1753863202...|\n",
            "|{\"id\": 1753863204...|\n",
            "|{\"id\": 472769508,...|\n",
            "|{\"id\": 1753863203...|\n",
            "|{\"id\": 272415891,...|\n",
            "|{\"id\": 1753863205...|\n",
            "|{\"id\": 86214474, ...|\n",
            "|{\"id\": 1753863206...|\n",
            "|{\"id\": 1753863207...|\n",
            "|{\"id\": 1753863208...|\n",
            "|{\"id\": 1989627639...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfWikiFinal.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dtafomArWOf"
      },
      "outputs": [],
      "source": [
        " from pyspark.sql.types import MapType, StringType \n",
        " from pyspark.sql.functions import from_json\n",
        " dfWikiJson = dfWikiFinal.withColumn(\"value\", from_json(dfWikiFinal.value, MapType(StringType(), StringType())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33RDhpUZt4dl",
        "outputId": "c0ebc31f-16a6-4697-d863-d368ddd7ddf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               value|\n",
            "+--------------------+\n",
            "|{id -> 1753863194...|\n",
            "|{id -> 150767170,...|\n",
            "|{id -> 1753863197...|\n",
            "|{id -> 1753863196...|\n",
            "|{id -> 1753863195...|\n",
            "|{id -> 1753863198...|\n",
            "|{id -> 1753863199...|\n",
            "|{id -> 1753863200...|\n",
            "|{id -> 1753863201...|\n",
            "|{id -> 1753863202...|\n",
            "|{id -> 1753863204...|\n",
            "|{id -> 472769508,...|\n",
            "|{id -> 1753863203...|\n",
            "|{id -> 272415891,...|\n",
            "|{id -> 1753863205...|\n",
            "|{id -> 86214474, ...|\n",
            "|{id -> 1753863206...|\n",
            "|{id -> 1753863207...|\n",
            "|{id -> 1753863208...|\n",
            "|{id -> 1989627639...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfWikiJson.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPLCFeWNtPOP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import explode\n",
        "df2 = dfWikiJson.select(dfWikiJson.value.alias(\"data\"),explode(dfWikiJson.value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thkiFFeDvhOA",
        "outputId": "8427ce8b-998d-4c0e-9dc0-498cf2ba48fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+---------------------------+\n",
            "|                data|       key|                      value|\n",
            "+--------------------+----------+---------------------------+\n",
            "|{id -> 1753863194...|        id|                 1753863194|\n",
            "|{id -> 1753863194...|    domain|           www.wikidata.org|\n",
            "|{id -> 1753863194...| namespace|             main namespace|\n",
            "|{id -> 1753863194...|     title|                  Q12499275|\n",
            "|{id -> 1753863194...| timestamp|       2022-08-10T15:37:22Z|\n",
            "|{id -> 1753863194...| user_name|               Danil Satria|\n",
            "|{id -> 1753863194...| user_type|                      human|\n",
            "|{id -> 1753863194...|old_length|                      22868|\n",
            "|{id -> 1753863194...|new_length|                      23321|\n",
            "|{id -> 150767170,...|        id|                  150767170|\n",
            "|{id -> 150767170,...|    domain|           zh.wikipedia.org|\n",
            "|{id -> 150767170,...| namespace|             main namespace|\n",
            "|{id -> 150767170,...|     title|中国大陆电视剧列表 (2022年)|\n",
            "|{id -> 150767170,...| timestamp|       2022-08-10T15:37:22Z|\n",
            "|{id -> 150767170,...| user_name|              Musicinsummer|\n",
            "|{id -> 150767170,...| user_type|                      human|\n",
            "|{id -> 150767170,...|old_length|                     217210|\n",
            "|{id -> 150767170,...|new_length|                     217210|\n",
            "|{id -> 1753863197...|        id|                 1753863197|\n",
            "|{id -> 1753863197...|    domain|           www.wikidata.org|\n",
            "+--------------------+----------+---------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df2.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV1dgCw4AXUb"
      },
      "outputs": [],
      "source": [
        "df3 = df2.select(df2.data.cast(\"string\"), df2.key, df2.value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IHkLsr_AqH4",
        "outputId": "d94b7259-90ee-4403-d5bb-d7156dcd1255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+---------------------------+\n",
            "|                data|       key|                      value|\n",
            "+--------------------+----------+---------------------------+\n",
            "|{id -> 1753863194...|        id|                 1753863194|\n",
            "|{id -> 1753863194...|    domain|           www.wikidata.org|\n",
            "|{id -> 1753863194...| namespace|             main namespace|\n",
            "|{id -> 1753863194...|     title|                  Q12499275|\n",
            "|{id -> 1753863194...| timestamp|       2022-08-10T15:37:22Z|\n",
            "|{id -> 1753863194...| user_name|               Danil Satria|\n",
            "|{id -> 1753863194...| user_type|                      human|\n",
            "|{id -> 1753863194...|old_length|                      22868|\n",
            "|{id -> 1753863194...|new_length|                      23321|\n",
            "|{id -> 150767170,...|        id|                  150767170|\n",
            "|{id -> 150767170,...|    domain|           zh.wikipedia.org|\n",
            "|{id -> 150767170,...| namespace|             main namespace|\n",
            "|{id -> 150767170,...|     title|中国大陆电视剧列表 (2022年)|\n",
            "|{id -> 150767170,...| timestamp|       2022-08-10T15:37:22Z|\n",
            "|{id -> 150767170,...| user_name|              Musicinsummer|\n",
            "|{id -> 150767170,...| user_type|                      human|\n",
            "|{id -> 150767170,...|old_length|                     217210|\n",
            "|{id -> 150767170,...|new_length|                     217210|\n",
            "|{id -> 1753863197...|        id|                 1753863197|\n",
            "|{id -> 1753863197...|    domain|           www.wikidata.org|\n",
            "+--------------------+----------+---------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df3.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiwMQYTeu7tp"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import first\n",
        "\n",
        "df4 = df3.groupby(df3.data).pivot(\"key\").agg(first(\"value\")).drop(df3.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRREyIIiuF_2",
        "outputId": "03729c8c-af6a-454b-cd32-aa5a460ef488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+\n",
            "|              domain|        id|     namespace|new_length|old_length|           timestamp|                      title|         user_name|user_type|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+\n",
            "|commons.wikimedia...|1989627639|          File|      4121|      3685|2022-08-10T15:37:23Z|       File:Schloß Neuha...|    BotMultichillT|      bot|\n",
            "|    www.wikidata.org|1753863203|main namespace|     28583|     35112|2022-08-10T15:37:19Z|                    Q374807|          HarryNº2|    human|\n",
            "|    www.wikidata.org|1753863212|main namespace|      3521|      2322|2022-08-10T15:37:23Z|                  Q10474681|               SR5|    human|\n",
            "|   arz.wikipedia.org|  39739901|main namespace|      3688|      3546|2022-08-10T15:37:22Z|       SHELS 012.969916+...|InternetArchiveBot|      bot|\n",
            "|    zh.wikipedia.org| 150767170|main namespace|    217210|    217210|2022-08-10T15:37:22Z|中国大陆电视剧列表 (2022年)|     Musicinsummer|    human|\n",
            "|    www.wikidata.org|1753863216|main namespace|     12345|     12759|2022-08-10T15:37:23Z|                  Q11039572|      Danil Satria|    human|\n",
            "|    www.wikidata.org|1753863217|main namespace|      6665|      5947|2022-08-10T15:37:23Z|                 Q108120566|     Thomasstjerne|    human|\n",
            "|    www.wikidata.org|1753863218|main namespace|     28435|     28437|2022-08-10T15:37:23Z|                  Q67817076|            Cewbot|      bot|\n",
            "|    www.wikidata.org|1753863199|main namespace|      7534|      6816|2022-08-10T15:37:22Z|                 Q108120555|     Thomasstjerne|    human|\n",
            "|    www.wikidata.org|1753863196|main namespace|     16044|     15911|2022-08-10T15:37:22Z|                  Q79330348|          Renamerr|    human|\n",
            "|    www.wikidata.org|1753863197|main namespace|     11797|     12211|2022-08-10T15:37:22Z|                  Q12514428|      Danil Satria|    human|\n",
            "|    www.wikidata.org|1753863194|main namespace|     23321|     22868|2022-08-10T15:37:22Z|                  Q12499275|      Danil Satria|    human|\n",
            "|    www.wikidata.org|1753863200|main namespace|     12047|     12461|2022-08-10T15:37:22Z|                  Q11039550|      Danil Satria|    human|\n",
            "|    www.wikidata.org|1753863207|main namespace|     23774|     23321|2022-08-10T15:37:23Z|                  Q12499275|      Danil Satria|    human|\n",
            "|    www.wikidata.org|1753863205|main namespace|      5190|      5204|2022-08-10T15:37:23Z|                 Q113487032|          Trilotat|    human|\n",
            "|    www.wikidata.org|1753863209|main namespace|     28437|     23876|2022-08-10T15:37:23Z|                  Q67817076|            Cewbot|      bot|\n",
            "|    www.wikidata.org|1753863202|main namespace|     23656|     23523|2022-08-10T15:37:23Z|                  Q73922375|          Renamerr|    human|\n",
            "|    en.wikipedia.org|1537382771|          Talk|      4058|      3419|2022-08-10T15:37:22Z|       Talk:Pan-American...|Community Tech bot|    human|\n",
            "|    www.wikidata.org|1753863201|main namespace|     10390|     10804|2022-08-10T15:37:22Z|                  Q19726398|      Danil Satria|    human|\n",
            "|simple.wikipedia.org|  18942085|main namespace|        92|        39|2022-08-10T15:37:22Z|       National aquatic ...|        MathXplore|    human|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df4.show()                                                                           "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPaKPSszj8Ud"
      },
      "source": [
        "## Aggregation with grouping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgxO9NAWj7Jw"
      },
      "outputs": [],
      "source": [
        "dfGroupDomain = df4.groupby(df4.domain).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1C7qtuoBvSg",
        "outputId": "0e7782ee-43a6-42f0-fa27-94c58d30d2bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|              domain|count|\n",
            "+--------------------+-----+\n",
            "|commons.wikimedia...|    4|\n",
            "|    en.wikipedia.org|    1|\n",
            "|    tr.wikipedia.org|    1|\n",
            "|    es.wikipedia.org|    2|\n",
            "|    no.wikipedia.org|    1|\n",
            "|   arz.wikipedia.org|    1|\n",
            "|    zh.wikipedia.org|    1|\n",
            "|    www.wikidata.org|   26|\n",
            "|    fr.wikipedia.org|    1|\n",
            "|simple.wikipedia.org|    1|\n",
            "+--------------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfGroupDomain.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfGroupDomainWrite = dfGroupDomain.select(create_map('domain', 'count').alias(\"value\"))"
      ],
      "metadata": {
        "id": "tDdp3bkDSv_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfGroupDomainWrite.selectExpr(\"CAST(value AS STRING)\") \\\n",
        "  .write \\\n",
        "  .format(\"kafka\") \\\n",
        "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
        "  .option(\"topic\", \"groupData\") \\\n",
        "  .save()"
      ],
      "metadata": {
        "id": "F4NSDxGQNLFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-t6EmHhUeK1"
      },
      "outputs": [],
      "source": [
        "dfGroupDomainNamespace = df4.groupby(df4.domain, df4.namespace).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUhrgFiMUm0t",
        "outputId": "1d32de4d-b239-495c-f48d-a538e0a77461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------+-----+\n",
            "|              domain|     namespace|count|\n",
            "+--------------------+--------------+-----+\n",
            "|    fr.wikipedia.org|main namespace|    1|\n",
            "|    en.wikipedia.org|          Talk|    1|\n",
            "|    www.wikidata.org|main namespace|   26|\n",
            "|simple.wikipedia.org|main namespace|    1|\n",
            "|    zh.wikipedia.org|main namespace|    1|\n",
            "|    no.wikipedia.org|main namespace|    1|\n",
            "|    es.wikipedia.org|main namespace|    2|\n",
            "|commons.wikimedia...|          File|    4|\n",
            "|    tr.wikipedia.org|main namespace|    1|\n",
            "|   arz.wikipedia.org|main namespace|    1|\n",
            "+--------------------+--------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfGroupDomainNamespace.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vzJHQSGpmCz"
      },
      "source": [
        "## Aggregation with Pivoting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKRCss4yplZU"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import first\n",
        "\n",
        "dfPivoting = df4.groupby(df4.id).pivot(\"user_type\").agg(first(\"user_name\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Uvi6ZHJWXYt",
        "outputId": "977de047-4934-42a9-8aae-92b31338bb48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+--------------+\n",
            "|        id|               bot|         human|\n",
            "+----------+------------------+--------------+\n",
            "|1753863203|              null|      HarryNº2|\n",
            "|1753863205|              null|      Trilotat|\n",
            "| 472769508|              null|      Pandamou|\n",
            "|1753863211|              null|  Danil Satria|\n",
            "|1753863219|              null|  Danil Satria|\n",
            "|1753863201|              null|  Danil Satria|\n",
            "|1753863200|              null|  Danil Satria|\n",
            "|1753863197|              null|  Danil Satria|\n",
            "|1753863196|              null|      Renamerr|\n",
            "|1753863218|            Cewbot|          null|\n",
            "|1989627640|     SchlurcherBot|          null|\n",
            "| 272415891|              null|190.139.97.212|\n",
            "|  18942085|              null|    MathXplore|\n",
            "|1753863210|              null|       Romaine|\n",
            "|1753863198|              null|          Yiyi|\n",
            "|1753863206|              null|  Danil Satria|\n",
            "|1753863209|            Cewbot|          null|\n",
            "|1753863212|              null|           SR5|\n",
            "|1989627639|    BotMultichillT|          null|\n",
            "| 272415892|InternetArchiveBot|          null|\n",
            "+----------+------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfPivoting.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nfcyrQtpqFZ"
      },
      "source": [
        "## Aggregation with rollups and cubes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1MURHtcTVIy"
      },
      "source": [
        "### Applying the rollup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lStXYVRfCKXR",
        "outputId": "3b2f635a-1879-49bd-9e1c-22ad5d3cbb4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|user_type|count|\n",
            "+---------+-----+\n",
            "|     null|   39|\n",
            "|    human|   30|\n",
            "|      bot|    9|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df4.rollup(df4.user_type).count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3laRnVnHD90q",
        "outputId": "316d5af3-628d-4c27-91da-06c97243510f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------+-----+\n",
            "|user_type|     namespace|count|\n",
            "+---------+--------------+-----+\n",
            "|    human|          Talk|    1|\n",
            "|    human|          null|   30|\n",
            "|      bot|          File|    3|\n",
            "|    human|main namespace|   28|\n",
            "|    human|          File|    1|\n",
            "|     null|          null|   39|\n",
            "|      bot|main namespace|    6|\n",
            "|      bot|          null|    9|\n",
            "+---------+--------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df4.rollup(df4.user_type, df4.namespace).count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPvBCLF0lzVy"
      },
      "source": [
        "### Applying the cube()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSJ93SuPDaPb",
        "outputId": "82841e6c-1215-4b5a-b5dc-a2dca6d7b1a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|user_type|count|\n",
            "+---------+-----+\n",
            "|     null|   39|\n",
            "|    human|   30|\n",
            "|      bot|    9|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df4.cube(df4.user_type).count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20-pJaKLCP2B",
        "outputId": "cf9879ac-4ae4-4aef-e2c8-4a0acca8593e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------+-----+\n",
            "|user_type|     namespace|count|\n",
            "+---------+--------------+-----+\n",
            "|    human|          Talk|    1|\n",
            "|    human|          null|   30|\n",
            "|      bot|          File|    3|\n",
            "|     null|          Talk|    1|\n",
            "|     null|main namespace|   34|\n",
            "|    human|main namespace|   28|\n",
            "|    human|          File|    1|\n",
            "|     null|          null|   39|\n",
            "|      bot|main namespace|    6|\n",
            "|     null|          File|    4|\n",
            "|      bot|          null|    9|\n",
            "+---------+--------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df4.cube(df4.user_type, df4.namespace).count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a8-Ey0vpucp"
      },
      "source": [
        "## Ranking functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ej6hu9dcCTFW"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.window import Window\n",
        "\n",
        "windowPartition = Window.partitionBy(\"user_name\").orderBy(\"new_length\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKS6KLeZk-Jk"
      },
      "source": [
        "### Applying the row_number() function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_516sOGGCU0"
      },
      "outputs": [],
      "source": [
        "dfRowNumber = df4.withColumn(\"row_number\",row_number().over(windowPartition))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOZZuLgpHjSC",
        "outputId": "c90d22db-f3ad-4f0f-df7a-f9d88c75e92b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+----------+\n",
            "|              domain|        id|     namespace|new_length|old_length|           timestamp|                      title|         user_name|user_type|row_number|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+----------+\n",
            "|    www.wikidata.org|1753863203|main namespace|     28583|     35112|2022-08-10T15:37:19Z|                    Q374807|          HarryNº2|    human|         1|\n",
            "|    en.wikipedia.org|1537382771|          Talk|      4058|      3419|2022-08-10T15:37:22Z|       Talk:Pan-American...|Community Tech bot|    human|         1|\n",
            "|commons.wikimedia...|1989627639|          File|      4121|      3685|2022-08-10T15:37:23Z|       File:Schloß Neuha...|    BotMultichillT|      bot|         1|\n",
            "|    www.wikidata.org|1753863205|main namespace|      5190|      5204|2022-08-10T15:37:23Z|                 Q113487032|          Trilotat|    human|         1|\n",
            "|   arz.wikipedia.org|  39739901|main namespace|      3688|      3546|2022-08-10T15:37:22Z|       SHELS 012.969916+...|InternetArchiveBot|      bot|         1|\n",
            "|    es.wikipedia.org| 272415892|main namespace|     37988|     37613|2022-08-10T15:37:22Z|       Sporting Clube de...|InternetArchiveBot|      bot|         2|\n",
            "|    www.wikidata.org|1753863198|main namespace|      1297|       876|2022-08-10T15:37:22Z|                 Q113487283|              Yiyi|    human|         1|\n",
            "|    www.wikidata.org|1753863217|main namespace|      6665|      5947|2022-08-10T15:37:23Z|                 Q108120566|     Thomasstjerne|    human|         1|\n",
            "|    www.wikidata.org|1753863199|main namespace|      7534|      6816|2022-08-10T15:37:22Z|                 Q108120555|     Thomasstjerne|    human|         2|\n",
            "|    es.wikipedia.org| 272415891|main namespace|      9943|      9940|2022-08-10T15:37:23Z|       Secretaría de Jus...|    190.139.97.212|    human|         1|\n",
            "|commons.wikimedia...|1989627642|          File|      9534|      9251|2022-08-10T15:37:23Z|       File:Groningen (s...|  Agnes Monkelbaan|    human|         1|\n",
            "|    www.wikidata.org|1753863196|main namespace|     16044|     15911|2022-08-10T15:37:22Z|                  Q79330348|          Renamerr|    human|         1|\n",
            "|    www.wikidata.org|1753863202|main namespace|     23656|     23523|2022-08-10T15:37:23Z|                  Q73922375|          Renamerr|    human|         2|\n",
            "|    www.wikidata.org|1753863215|main namespace|     27850|     27717|2022-08-10T15:37:23Z|                  Q73923087|          Renamerr|    human|         3|\n",
            "|    www.wikidata.org|1753863195|main namespace|     29550|     29417|2022-08-10T15:37:22Z|                  Q72259451|          Renamerr|    human|         4|\n",
            "|    www.wikidata.org|1753863214|main namespace|     63840|     63707|2022-08-10T15:37:23Z|                  Q79330505|          Renamerr|    human|         5|\n",
            "|    www.wikidata.org|1753863208|main namespace|     33725|     34427|2022-08-10T15:37:23Z|                  Q88710664|     Twofivesixbot|      bot|         1|\n",
            "|simple.wikipedia.org|  18942085|main namespace|        92|        39|2022-08-10T15:37:22Z|       National aquatic ...|        MathXplore|    human|         1|\n",
            "|    zh.wikipedia.org| 150767170|main namespace|    217210|    217210|2022-08-10T15:37:22Z|中国大陆电视剧列表 (2022年)|     Musicinsummer|    human|         1|\n",
            "|    no.wikipedia.org|  86214474|main namespace|      1686|      1592|2022-08-10T15:37:22Z|       Mummitrollet (figur)|        Annelingua|    human|         1|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfRowNumber.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vnh1VEZeHgIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce640af7-8969-483f-facb-525aa3f0c1f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+----------+\n",
            "|              domain|        id|     namespace|new_length|old_length|           timestamp|                      title|         user_name|user_type|row_number|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+----------+\n",
            "|    www.wikidata.org|1753863203|main namespace|     28583|     35112|2022-08-10T15:37:19Z|                    Q374807|          HarryNº2|    human|         1|\n",
            "|    en.wikipedia.org|1537382771|          Talk|      4058|      3419|2022-08-10T15:37:22Z|       Talk:Pan-American...|Community Tech bot|    human|         1|\n",
            "|commons.wikimedia...|1989627639|          File|      4121|      3685|2022-08-10T15:37:23Z|       File:Schloß Neuha...|    BotMultichillT|      bot|         1|\n",
            "|    www.wikidata.org|1753863205|main namespace|      5190|      5204|2022-08-10T15:37:23Z|                 Q113487032|          Trilotat|    human|         1|\n",
            "|   arz.wikipedia.org|  39739901|main namespace|      3688|      3546|2022-08-10T15:37:22Z|       SHELS 012.969916+...|InternetArchiveBot|      bot|         1|\n",
            "|    www.wikidata.org|1753863198|main namespace|      1297|       876|2022-08-10T15:37:22Z|                 Q113487283|              Yiyi|    human|         1|\n",
            "|    www.wikidata.org|1753863217|main namespace|      6665|      5947|2022-08-10T15:37:23Z|                 Q108120566|     Thomasstjerne|    human|         1|\n",
            "|    es.wikipedia.org| 272415891|main namespace|      9943|      9940|2022-08-10T15:37:23Z|       Secretaría de Jus...|    190.139.97.212|    human|         1|\n",
            "|commons.wikimedia...|1989627642|          File|      9534|      9251|2022-08-10T15:37:23Z|       File:Groningen (s...|  Agnes Monkelbaan|    human|         1|\n",
            "|    www.wikidata.org|1753863196|main namespace|     16044|     15911|2022-08-10T15:37:22Z|                  Q79330348|          Renamerr|    human|         1|\n",
            "|    www.wikidata.org|1753863208|main namespace|     33725|     34427|2022-08-10T15:37:23Z|                  Q88710664|     Twofivesixbot|      bot|         1|\n",
            "|simple.wikipedia.org|  18942085|main namespace|        92|        39|2022-08-10T15:37:22Z|       National aquatic ...|        MathXplore|    human|         1|\n",
            "|    zh.wikipedia.org| 150767170|main namespace|    217210|    217210|2022-08-10T15:37:22Z|中国大陆电视剧列表 (2022年)|     Musicinsummer|    human|         1|\n",
            "|    no.wikipedia.org|  86214474|main namespace|      1686|      1592|2022-08-10T15:37:22Z|       Mummitrollet (figur)|        Annelingua|    human|         1|\n",
            "|commons.wikimedia...|1989627640|          File|      6514|      2474|2022-08-10T15:37:23Z|       File:Hello Again ...|     SchlurcherBot|      bot|         1|\n",
            "|    tr.wikipedia.org|  54210546|main namespace|     12427|     12447|2022-08-10T15:37:22Z|            Akoluk, Tuzluca|              YBot|      bot|         1|\n",
            "|commons.wikimedia...|1989627641|          File|     10048|     10466|2022-08-10T15:37:23Z|       File:ISS030-E-160...|           AskeBot|      bot|         1|\n",
            "|    www.wikidata.org|1753863212|main namespace|      3521|      2322|2022-08-10T15:37:23Z|                  Q10474681|               SR5|    human|         1|\n",
            "|    fr.wikipedia.org| 472769508|main namespace|      8769|      8877|2022-08-10T15:37:21Z|       Cité de la musiqu...|          Pandamou|    human|         1|\n",
            "|    www.wikidata.org|1753863201|main namespace|     10390|     10804|2022-08-10T15:37:22Z|                  Q19726398|      Danil Satria|    human|         1|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dfRowNumber.filter(dfRowNumber.row_number == 1).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XHmcFTllG67"
      },
      "source": [
        "### Applying the rank() function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAC2vuKcIGIL",
        "outputId": "15585b12-4dba-4af3-e01d-c3907c32524f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+----+\n",
            "|              domain|        id|     namespace|new_length|old_length|           timestamp|                      title|         user_name|user_type|rank|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+----+\n",
            "|    www.wikidata.org|1753863203|main namespace|     28583|     35112|2022-08-10T15:37:19Z|                    Q374807|          HarryNº2|    human|   1|\n",
            "|    en.wikipedia.org|1537382771|          Talk|      4058|      3419|2022-08-10T15:37:22Z|       Talk:Pan-American...|Community Tech bot|    human|   1|\n",
            "|commons.wikimedia...|1989627639|          File|      4121|      3685|2022-08-10T15:37:23Z|       File:Schloß Neuha...|    BotMultichillT|      bot|   1|\n",
            "|    www.wikidata.org|1753863205|main namespace|      5190|      5204|2022-08-10T15:37:23Z|                 Q113487032|          Trilotat|    human|   1|\n",
            "|   arz.wikipedia.org|  39739901|main namespace|      3688|      3546|2022-08-10T15:37:22Z|       SHELS 012.969916+...|InternetArchiveBot|      bot|   1|\n",
            "|    es.wikipedia.org| 272415892|main namespace|     37988|     37613|2022-08-10T15:37:22Z|       Sporting Clube de...|InternetArchiveBot|      bot|   2|\n",
            "|    www.wikidata.org|1753863198|main namespace|      1297|       876|2022-08-10T15:37:22Z|                 Q113487283|              Yiyi|    human|   1|\n",
            "|    www.wikidata.org|1753863217|main namespace|      6665|      5947|2022-08-10T15:37:23Z|                 Q108120566|     Thomasstjerne|    human|   1|\n",
            "|    www.wikidata.org|1753863199|main namespace|      7534|      6816|2022-08-10T15:37:22Z|                 Q108120555|     Thomasstjerne|    human|   2|\n",
            "|    es.wikipedia.org| 272415891|main namespace|      9943|      9940|2022-08-10T15:37:23Z|       Secretaría de Jus...|    190.139.97.212|    human|   1|\n",
            "|commons.wikimedia...|1989627642|          File|      9534|      9251|2022-08-10T15:37:23Z|       File:Groningen (s...|  Agnes Monkelbaan|    human|   1|\n",
            "|    www.wikidata.org|1753863196|main namespace|     16044|     15911|2022-08-10T15:37:22Z|                  Q79330348|          Renamerr|    human|   1|\n",
            "|    www.wikidata.org|1753863202|main namespace|     23656|     23523|2022-08-10T15:37:23Z|                  Q73922375|          Renamerr|    human|   2|\n",
            "|    www.wikidata.org|1753863215|main namespace|     27850|     27717|2022-08-10T15:37:23Z|                  Q73923087|          Renamerr|    human|   3|\n",
            "|    www.wikidata.org|1753863195|main namespace|     29550|     29417|2022-08-10T15:37:22Z|                  Q72259451|          Renamerr|    human|   4|\n",
            "|    www.wikidata.org|1753863214|main namespace|     63840|     63707|2022-08-10T15:37:23Z|                  Q79330505|          Renamerr|    human|   5|\n",
            "|    www.wikidata.org|1753863208|main namespace|     33725|     34427|2022-08-10T15:37:23Z|                  Q88710664|     Twofivesixbot|      bot|   1|\n",
            "|simple.wikipedia.org|  18942085|main namespace|        92|        39|2022-08-10T15:37:22Z|       National aquatic ...|        MathXplore|    human|   1|\n",
            "|    zh.wikipedia.org| 150767170|main namespace|    217210|    217210|2022-08-10T15:37:22Z|中国大陆电视剧列表 (2022年)|     Musicinsummer|    human|   1|\n",
            "|    no.wikipedia.org|  86214474|main namespace|      1686|      1592|2022-08-10T15:37:22Z|       Mummitrollet (figur)|        Annelingua|    human|   1|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import rank\n",
        " \n",
        "df4.withColumn(\"rank\", rank().over(windowPartition)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-tyvO0DlUKj"
      },
      "source": [
        "### Applying the percent_rank() function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "716W-YCIIdGR",
        "outputId": "28743255-1ee1-4179-bb16-c53dd538e9d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+------------+\n",
            "|              domain|        id|     namespace|new_length|old_length|           timestamp|                      title|         user_name|user_type|percent_rank|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+------------+\n",
            "|    www.wikidata.org|1753863203|main namespace|     28583|     35112|2022-08-10T15:37:19Z|                    Q374807|          HarryNº2|    human|         0.0|\n",
            "|    en.wikipedia.org|1537382771|          Talk|      4058|      3419|2022-08-10T15:37:22Z|       Talk:Pan-American...|Community Tech bot|    human|         0.0|\n",
            "|commons.wikimedia...|1989627639|          File|      4121|      3685|2022-08-10T15:37:23Z|       File:Schloß Neuha...|    BotMultichillT|      bot|         0.0|\n",
            "|    www.wikidata.org|1753863205|main namespace|      5190|      5204|2022-08-10T15:37:23Z|                 Q113487032|          Trilotat|    human|         0.0|\n",
            "|   arz.wikipedia.org|  39739901|main namespace|      3688|      3546|2022-08-10T15:37:22Z|       SHELS 012.969916+...|InternetArchiveBot|      bot|         0.0|\n",
            "|    es.wikipedia.org| 272415892|main namespace|     37988|     37613|2022-08-10T15:37:22Z|       Sporting Clube de...|InternetArchiveBot|      bot|         1.0|\n",
            "|    www.wikidata.org|1753863198|main namespace|      1297|       876|2022-08-10T15:37:22Z|                 Q113487283|              Yiyi|    human|         0.0|\n",
            "|    www.wikidata.org|1753863217|main namespace|      6665|      5947|2022-08-10T15:37:23Z|                 Q108120566|     Thomasstjerne|    human|         0.0|\n",
            "|    www.wikidata.org|1753863199|main namespace|      7534|      6816|2022-08-10T15:37:22Z|                 Q108120555|     Thomasstjerne|    human|         1.0|\n",
            "|    es.wikipedia.org| 272415891|main namespace|      9943|      9940|2022-08-10T15:37:23Z|       Secretaría de Jus...|    190.139.97.212|    human|         0.0|\n",
            "|commons.wikimedia...|1989627642|          File|      9534|      9251|2022-08-10T15:37:23Z|       File:Groningen (s...|  Agnes Monkelbaan|    human|         0.0|\n",
            "|    www.wikidata.org|1753863196|main namespace|     16044|     15911|2022-08-10T15:37:22Z|                  Q79330348|          Renamerr|    human|         0.0|\n",
            "|    www.wikidata.org|1753863202|main namespace|     23656|     23523|2022-08-10T15:37:23Z|                  Q73922375|          Renamerr|    human|        0.25|\n",
            "|    www.wikidata.org|1753863215|main namespace|     27850|     27717|2022-08-10T15:37:23Z|                  Q73923087|          Renamerr|    human|         0.5|\n",
            "|    www.wikidata.org|1753863195|main namespace|     29550|     29417|2022-08-10T15:37:22Z|                  Q72259451|          Renamerr|    human|        0.75|\n",
            "|    www.wikidata.org|1753863214|main namespace|     63840|     63707|2022-08-10T15:37:23Z|                  Q79330505|          Renamerr|    human|         1.0|\n",
            "|    www.wikidata.org|1753863208|main namespace|     33725|     34427|2022-08-10T15:37:23Z|                  Q88710664|     Twofivesixbot|      bot|         0.0|\n",
            "|simple.wikipedia.org|  18942085|main namespace|        92|        39|2022-08-10T15:37:22Z|       National aquatic ...|        MathXplore|    human|         0.0|\n",
            "|    zh.wikipedia.org| 150767170|main namespace|    217210|    217210|2022-08-10T15:37:22Z|中国大陆电视剧列表 (2022年)|     Musicinsummer|    human|         0.0|\n",
            "|    no.wikipedia.org|  86214474|main namespace|      1686|      1592|2022-08-10T15:37:22Z|       Mummitrollet (figur)|        Annelingua|    human|         0.0|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import percent_rank\n",
        "\n",
        "df4.withColumn(\"percent_rank\",percent_rank().over(windowPartition)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxaHLctola7X"
      },
      "source": [
        "### Applying the dense_rank() function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyHVcK3kIuV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aabe1c4-0bdc-4850-a651-0147e9a553f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+----------+\n",
            "|              domain|        id|     namespace|new_length|old_length|           timestamp|                      title|         user_name|user_type|dense_rank|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+----------+\n",
            "|    www.wikidata.org|1753863203|main namespace|     28583|     35112|2022-08-10T15:37:19Z|                    Q374807|          HarryNº2|    human|         1|\n",
            "|    en.wikipedia.org|1537382771|          Talk|      4058|      3419|2022-08-10T15:37:22Z|       Talk:Pan-American...|Community Tech bot|    human|         1|\n",
            "|commons.wikimedia...|1989627639|          File|      4121|      3685|2022-08-10T15:37:23Z|       File:Schloß Neuha...|    BotMultichillT|      bot|         1|\n",
            "|    www.wikidata.org|1753863205|main namespace|      5190|      5204|2022-08-10T15:37:23Z|                 Q113487032|          Trilotat|    human|         1|\n",
            "|   arz.wikipedia.org|  39739901|main namespace|      3688|      3546|2022-08-10T15:37:22Z|       SHELS 012.969916+...|InternetArchiveBot|      bot|         1|\n",
            "|    es.wikipedia.org| 272415892|main namespace|     37988|     37613|2022-08-10T15:37:22Z|       Sporting Clube de...|InternetArchiveBot|      bot|         2|\n",
            "|    www.wikidata.org|1753863198|main namespace|      1297|       876|2022-08-10T15:37:22Z|                 Q113487283|              Yiyi|    human|         1|\n",
            "|    www.wikidata.org|1753863217|main namespace|      6665|      5947|2022-08-10T15:37:23Z|                 Q108120566|     Thomasstjerne|    human|         1|\n",
            "|    www.wikidata.org|1753863199|main namespace|      7534|      6816|2022-08-10T15:37:22Z|                 Q108120555|     Thomasstjerne|    human|         2|\n",
            "|    es.wikipedia.org| 272415891|main namespace|      9943|      9940|2022-08-10T15:37:23Z|       Secretaría de Jus...|    190.139.97.212|    human|         1|\n",
            "|commons.wikimedia...|1989627642|          File|      9534|      9251|2022-08-10T15:37:23Z|       File:Groningen (s...|  Agnes Monkelbaan|    human|         1|\n",
            "|    www.wikidata.org|1753863196|main namespace|     16044|     15911|2022-08-10T15:37:22Z|                  Q79330348|          Renamerr|    human|         1|\n",
            "|    www.wikidata.org|1753863202|main namespace|     23656|     23523|2022-08-10T15:37:23Z|                  Q73922375|          Renamerr|    human|         2|\n",
            "|    www.wikidata.org|1753863215|main namespace|     27850|     27717|2022-08-10T15:37:23Z|                  Q73923087|          Renamerr|    human|         3|\n",
            "|    www.wikidata.org|1753863195|main namespace|     29550|     29417|2022-08-10T15:37:22Z|                  Q72259451|          Renamerr|    human|         4|\n",
            "|    www.wikidata.org|1753863214|main namespace|     63840|     63707|2022-08-10T15:37:23Z|                  Q79330505|          Renamerr|    human|         5|\n",
            "|    www.wikidata.org|1753863208|main namespace|     33725|     34427|2022-08-10T15:37:23Z|                  Q88710664|     Twofivesixbot|      bot|         1|\n",
            "|simple.wikipedia.org|  18942085|main namespace|        92|        39|2022-08-10T15:37:22Z|       National aquatic ...|        MathXplore|    human|         1|\n",
            "|    zh.wikipedia.org| 150767170|main namespace|    217210|    217210|2022-08-10T15:37:22Z|中国大陆电视剧列表 (2022年)|     Musicinsummer|    human|         1|\n",
            "|    no.wikipedia.org|  86214474|main namespace|      1686|      1592|2022-08-10T15:37:22Z|       Mummitrollet (figur)|        Annelingua|    human|         1|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import dense_rank\n",
        " \n",
        "df4.withColumn(\"dense_rank\",dense_rank().over(windowPartition)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fA0y-Zap07a"
      },
      "source": [
        "## Analytic functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsnkGMSBl8VH"
      },
      "source": [
        "### Applying the cume_dist() functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQWMniCydx6-",
        "outputId": "ce16a484-8255-4371-f899-745b559105ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+---------+\n",
            "|              domain|        id|     namespace|new_length|old_length|           timestamp|                      title|         user_name|user_type|cume_dist|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+---------+\n",
            "|    www.wikidata.org|1753863203|main namespace|     28583|     35112|2022-08-10T15:37:19Z|                    Q374807|          HarryNº2|    human|      1.0|\n",
            "|    en.wikipedia.org|1537382771|          Talk|      4058|      3419|2022-08-10T15:37:22Z|       Talk:Pan-American...|Community Tech bot|    human|      1.0|\n",
            "|commons.wikimedia...|1989627639|          File|      4121|      3685|2022-08-10T15:37:23Z|       File:Schloß Neuha...|    BotMultichillT|      bot|      1.0|\n",
            "|    www.wikidata.org|1753863205|main namespace|      5190|      5204|2022-08-10T15:37:23Z|                 Q113487032|          Trilotat|    human|      1.0|\n",
            "|   arz.wikipedia.org|  39739901|main namespace|      3688|      3546|2022-08-10T15:37:22Z|       SHELS 012.969916+...|InternetArchiveBot|      bot|      0.5|\n",
            "|    es.wikipedia.org| 272415892|main namespace|     37988|     37613|2022-08-10T15:37:22Z|       Sporting Clube de...|InternetArchiveBot|      bot|      1.0|\n",
            "|    www.wikidata.org|1753863198|main namespace|      1297|       876|2022-08-10T15:37:22Z|                 Q113487283|              Yiyi|    human|      1.0|\n",
            "|    www.wikidata.org|1753863217|main namespace|      6665|      5947|2022-08-10T15:37:23Z|                 Q108120566|     Thomasstjerne|    human|      0.5|\n",
            "|    www.wikidata.org|1753863199|main namespace|      7534|      6816|2022-08-10T15:37:22Z|                 Q108120555|     Thomasstjerne|    human|      1.0|\n",
            "|    es.wikipedia.org| 272415891|main namespace|      9943|      9940|2022-08-10T15:37:23Z|       Secretaría de Jus...|    190.139.97.212|    human|      1.0|\n",
            "|commons.wikimedia...|1989627642|          File|      9534|      9251|2022-08-10T15:37:23Z|       File:Groningen (s...|  Agnes Monkelbaan|    human|      1.0|\n",
            "|    www.wikidata.org|1753863196|main namespace|     16044|     15911|2022-08-10T15:37:22Z|                  Q79330348|          Renamerr|    human|      0.2|\n",
            "|    www.wikidata.org|1753863202|main namespace|     23656|     23523|2022-08-10T15:37:23Z|                  Q73922375|          Renamerr|    human|      0.4|\n",
            "|    www.wikidata.org|1753863215|main namespace|     27850|     27717|2022-08-10T15:37:23Z|                  Q73923087|          Renamerr|    human|      0.6|\n",
            "|    www.wikidata.org|1753863195|main namespace|     29550|     29417|2022-08-10T15:37:22Z|                  Q72259451|          Renamerr|    human|      0.8|\n",
            "|    www.wikidata.org|1753863214|main namespace|     63840|     63707|2022-08-10T15:37:23Z|                  Q79330505|          Renamerr|    human|      1.0|\n",
            "|    www.wikidata.org|1753863208|main namespace|     33725|     34427|2022-08-10T15:37:23Z|                  Q88710664|     Twofivesixbot|      bot|      1.0|\n",
            "|simple.wikipedia.org|  18942085|main namespace|        92|        39|2022-08-10T15:37:22Z|       National aquatic ...|        MathXplore|    human|      1.0|\n",
            "|    zh.wikipedia.org| 150767170|main namespace|    217210|    217210|2022-08-10T15:37:22Z|中国大陆电视剧列表 (2022年)|     Musicinsummer|    human|      1.0|\n",
            "|    no.wikipedia.org|  86214474|main namespace|      1686|      1592|2022-08-10T15:37:22Z|       Mummitrollet (figur)|        Annelingua|    human|      1.0|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import cume_dist\n",
        " \n",
        "df4.withColumn(\"cume_dist\",cume_dist().over(windowPartition)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3pnZRkcmF5t"
      },
      "source": [
        "### Applying the lag() functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVkejMLDKFTZ",
        "outputId": "15f88a56-c0f1-43e5-c2ef-b4d7a6e81c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+-----+\n",
            "|              domain|        id|     namespace|new_length|old_length|           timestamp|                      title|         user_name|user_type|  Lag|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+-----+\n",
            "|    www.wikidata.org|1753863203|main namespace|     28583|     35112|2022-08-10T15:37:19Z|                    Q374807|          HarryNº2|    human| null|\n",
            "|    en.wikipedia.org|1537382771|          Talk|      4058|      3419|2022-08-10T15:37:22Z|       Talk:Pan-American...|Community Tech bot|    human| null|\n",
            "|commons.wikimedia...|1989627639|          File|      4121|      3685|2022-08-10T15:37:23Z|       File:Schloß Neuha...|    BotMultichillT|      bot| null|\n",
            "|    www.wikidata.org|1753863205|main namespace|      5190|      5204|2022-08-10T15:37:23Z|                 Q113487032|          Trilotat|    human| null|\n",
            "|   arz.wikipedia.org|  39739901|main namespace|      3688|      3546|2022-08-10T15:37:22Z|       SHELS 012.969916+...|InternetArchiveBot|      bot| null|\n",
            "|    es.wikipedia.org| 272415892|main namespace|     37988|     37613|2022-08-10T15:37:22Z|       Sporting Clube de...|InternetArchiveBot|      bot| null|\n",
            "|    www.wikidata.org|1753863198|main namespace|      1297|       876|2022-08-10T15:37:22Z|                 Q113487283|              Yiyi|    human| null|\n",
            "|    www.wikidata.org|1753863217|main namespace|      6665|      5947|2022-08-10T15:37:23Z|                 Q108120566|     Thomasstjerne|    human| null|\n",
            "|    www.wikidata.org|1753863199|main namespace|      7534|      6816|2022-08-10T15:37:22Z|                 Q108120555|     Thomasstjerne|    human| null|\n",
            "|    es.wikipedia.org| 272415891|main namespace|      9943|      9940|2022-08-10T15:37:23Z|       Secretaría de Jus...|    190.139.97.212|    human| null|\n",
            "|commons.wikimedia...|1989627642|          File|      9534|      9251|2022-08-10T15:37:23Z|       File:Groningen (s...|  Agnes Monkelbaan|    human| null|\n",
            "|    www.wikidata.org|1753863196|main namespace|     16044|     15911|2022-08-10T15:37:22Z|                  Q79330348|          Renamerr|    human| null|\n",
            "|    www.wikidata.org|1753863202|main namespace|     23656|     23523|2022-08-10T15:37:23Z|                  Q73922375|          Renamerr|    human| null|\n",
            "|    www.wikidata.org|1753863215|main namespace|     27850|     27717|2022-08-10T15:37:23Z|                  Q73923087|          Renamerr|    human|15911|\n",
            "|    www.wikidata.org|1753863195|main namespace|     29550|     29417|2022-08-10T15:37:22Z|                  Q72259451|          Renamerr|    human|23523|\n",
            "|    www.wikidata.org|1753863214|main namespace|     63840|     63707|2022-08-10T15:37:23Z|                  Q79330505|          Renamerr|    human|27717|\n",
            "|    www.wikidata.org|1753863208|main namespace|     33725|     34427|2022-08-10T15:37:23Z|                  Q88710664|     Twofivesixbot|      bot| null|\n",
            "|simple.wikipedia.org|  18942085|main namespace|        92|        39|2022-08-10T15:37:22Z|       National aquatic ...|        MathXplore|    human| null|\n",
            "|    zh.wikipedia.org| 150767170|main namespace|    217210|    217210|2022-08-10T15:37:22Z|中国大陆电视剧列表 (2022年)|     Musicinsummer|    human| null|\n",
            "|    no.wikipedia.org|  86214474|main namespace|      1686|      1592|2022-08-10T15:37:22Z|       Mummitrollet (figur)|        Annelingua|    human| null|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import lag\n",
        " \n",
        "df4.withColumn(\"Lag\", lag(\"old_length\",2).over(windowPartition)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltjXE5lvmKjc"
      },
      "source": [
        "### Applying the lead() functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIeL0MI5Lbb2",
        "outputId": "3840cdfb-5f0d-4255-c0b1-b704a1493dbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+-----+\n",
            "|              domain|        id|     namespace|new_length|old_length|           timestamp|                      title|         user_name|user_type| Lead|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+-----+\n",
            "|    www.wikidata.org|1753863203|main namespace|     28583|     35112|2022-08-10T15:37:19Z|                    Q374807|          HarryNº2|    human| null|\n",
            "|    en.wikipedia.org|1537382771|          Talk|      4058|      3419|2022-08-10T15:37:22Z|       Talk:Pan-American...|Community Tech bot|    human| null|\n",
            "|commons.wikimedia...|1989627639|          File|      4121|      3685|2022-08-10T15:37:23Z|       File:Schloß Neuha...|    BotMultichillT|      bot| null|\n",
            "|    www.wikidata.org|1753863205|main namespace|      5190|      5204|2022-08-10T15:37:23Z|                 Q113487032|          Trilotat|    human| null|\n",
            "|   arz.wikipedia.org|  39739901|main namespace|      3688|      3546|2022-08-10T15:37:22Z|       SHELS 012.969916+...|InternetArchiveBot|      bot| null|\n",
            "|    es.wikipedia.org| 272415892|main namespace|     37988|     37613|2022-08-10T15:37:22Z|       Sporting Clube de...|InternetArchiveBot|      bot| null|\n",
            "|    www.wikidata.org|1753863198|main namespace|      1297|       876|2022-08-10T15:37:22Z|                 Q113487283|              Yiyi|    human| null|\n",
            "|    www.wikidata.org|1753863217|main namespace|      6665|      5947|2022-08-10T15:37:23Z|                 Q108120566|     Thomasstjerne|    human| null|\n",
            "|    www.wikidata.org|1753863199|main namespace|      7534|      6816|2022-08-10T15:37:22Z|                 Q108120555|     Thomasstjerne|    human| null|\n",
            "|    es.wikipedia.org| 272415891|main namespace|      9943|      9940|2022-08-10T15:37:23Z|       Secretaría de Jus...|    190.139.97.212|    human| null|\n",
            "|commons.wikimedia...|1989627642|          File|      9534|      9251|2022-08-10T15:37:23Z|       File:Groningen (s...|  Agnes Monkelbaan|    human| null|\n",
            "|    www.wikidata.org|1753863196|main namespace|     16044|     15911|2022-08-10T15:37:22Z|                  Q79330348|          Renamerr|    human|27717|\n",
            "|    www.wikidata.org|1753863202|main namespace|     23656|     23523|2022-08-10T15:37:23Z|                  Q73922375|          Renamerr|    human|29417|\n",
            "|    www.wikidata.org|1753863215|main namespace|     27850|     27717|2022-08-10T15:37:23Z|                  Q73923087|          Renamerr|    human|63707|\n",
            "|    www.wikidata.org|1753863195|main namespace|     29550|     29417|2022-08-10T15:37:22Z|                  Q72259451|          Renamerr|    human| null|\n",
            "|    www.wikidata.org|1753863214|main namespace|     63840|     63707|2022-08-10T15:37:23Z|                  Q79330505|          Renamerr|    human| null|\n",
            "|    www.wikidata.org|1753863208|main namespace|     33725|     34427|2022-08-10T15:37:23Z|                  Q88710664|     Twofivesixbot|      bot| null|\n",
            "|simple.wikipedia.org|  18942085|main namespace|        92|        39|2022-08-10T15:37:22Z|       National aquatic ...|        MathXplore|    human| null|\n",
            "|    zh.wikipedia.org| 150767170|main namespace|    217210|    217210|2022-08-10T15:37:22Z|中国大陆电视剧列表 (2022年)|     Musicinsummer|    human| null|\n",
            "|    no.wikipedia.org|  86214474|main namespace|      1686|      1592|2022-08-10T15:37:22Z|       Mummitrollet (figur)|        Annelingua|    human| null|\n",
            "+--------------------+----------+--------------+----------+----------+--------------------+---------------------------+------------------+---------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import lead\n",
        " \n",
        "df4.withColumn(\"Lead\", lead(\"old_length\", 2).over(windowPartition)).show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Pyspark-Kafka-1.0.0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}